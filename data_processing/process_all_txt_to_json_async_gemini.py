"""
result í´ë”ì˜ ëª¨ë“  txt íŒŒì¼ì„ JSONìœ¼ë¡œ ë³€í™˜í•˜ì—¬ result_txtì— ì €ì¥ (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ - Gemini ë²„ì „)

ì‚¬ìš©ë²•:
    python process_all_txt_to_json_async_gemini.py

íŠ¹ì§•:
    - Gemini 2.5 Flash ì‚¬ìš© (ë” ë¹ ë¥´ê³  ì €ë ´)
    - ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ
    - ë™ì‹œ ì²˜ë¦¬ ê°œìˆ˜ ì œí•œ (ê¸°ë³¸ 10ê°œ, ì¡°ì ˆ ê°€ëŠ¥)
    - ì§„í–‰ë¥  í‘œì‹œ
    - max_tokens: 65536 (Gemini 2.5 Flash ìµœëŒ€ ì¶œë ¥)
"""

import os
import asyncio
from pathlib import Path
from extract_metadata_from_txt_gemini import extract_metadata_with_llm
from dotenv import load_dotenv
from datetime import datetime
import time

load_dotenv()


async def process_single_file(
    txt_file: Path,
    api_key: str,
    model: str,
    max_tokens: int,
    idx: int,
    total: int
) -> tuple[bool, str]:
    """
    ë‹¨ì¼ txt íŒŒì¼ì„ JSONìœ¼ë¡œ ë³€í™˜ (ë¹„ë™ê¸°)

    Args:
        txt_file: txt íŒŒì¼ ê²½ë¡œ
        api_key: Google API í‚¤
        model: ì‚¬ìš©í•  Gemini ëª¨ë¸
        max_tokens: ìµœëŒ€ ì¶œë ¥ í† í°
        idx: í˜„ì¬ íŒŒì¼ ì¸ë±ìŠ¤
        total: ì „ì²´ íŒŒì¼ ê°œìˆ˜

    Returns:
        (ì„±ê³µ ì—¬ë¶€, ë©”ì‹œì§€)
    """
    try:
        print(f"[{idx}/{total}] ì²˜ë¦¬ ì‹œì‘: {txt_file.name}")

        # asyncio.to_threadë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
        result = await asyncio.to_thread(
            extract_metadata_with_llm,
            txt_path=str(txt_file),
            api_key=api_key,
            model=model,
            max_tokens=max_tokens
        )

        if result:
            msg = f"âœ… [{idx}/{total}] ì„±ê³µ: {txt_file.name} â†’ result_txt/{txt_file.stem}.json"
            print(msg)
            return (True, msg)
        else:
            msg = f"âŒ [{idx}/{total}] ì‹¤íŒ¨: {txt_file.name}"
            print(msg)
            return (False, msg)

    except Exception as e:
        msg = f"âŒ [{idx}/{total}] ì˜¤ë¥˜: {txt_file.name} - {str(e)}"
        print(msg)
        return (False, msg)


async def process_all_txt_files_async(
    result_dir: str = "result",
    api_key: str = None,
    model: str = "gemini-2.5-flash",
    max_tokens: int = 65536,  # Gemini 2.5 Flash ìµœëŒ€ ì¶œë ¥ í† í°
    max_concurrent: int = 10  # GeminiëŠ” OpenAIë³´ë‹¤ rate limit ì—¬ìœ ë¡œì›€
):
    """
    result í´ë”ì˜ ëª¨ë“  txt íŒŒì¼ì„ JSONìœ¼ë¡œ ë³€í™˜ (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ - Gemini)

    Args:
        result_dir: result í´ë” ê²½ë¡œ
        api_key: Google API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
        model: ì‚¬ìš©í•  Gemini ëª¨ë¸
        max_tokens: ìµœëŒ€ ì¶œë ¥ í† í° (Gemini 2.5 FlashëŠ” 65536ê¹Œì§€ ê°€ëŠ¥)
        max_concurrent: ë™ì‹œ ì²˜ë¦¬ ê°œìˆ˜ (ê¸°ë³¸ 10ê°œ)
    """
    # API í‚¤ í™•ì¸
    if not api_key:
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            print("âŒ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            return

    print("=" * 80)
    print("result í´ë” txt íŒŒì¼ â†’ JSON ë³€í™˜ ì‹œì‘ (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ - Gemini)")
    print("=" * 80)
    print(f"ğŸ¤– ëª¨ë¸: {model}")
    print(f"ğŸ“Š ìµœëŒ€ ì¶œë ¥ í† í°: {max_tokens}")
    print(f"âš™ï¸  ë™ì‹œ ì²˜ë¦¬ ê°œìˆ˜: {max_concurrent}ê°œ")
    print()

    # result í´ë”ì˜ ëª¨ë“  í•˜ìœ„ í´ë” íƒìƒ‰
    result_path = Path(result_dir)
    txt_files = []

    for folder in result_path.iterdir():
        if folder.is_dir():
            # ê° í´ë”ì˜ txt íŒŒì¼ ì°¾ê¸°
            for file in folder.glob("*.txt"):
                txt_files.append(file)

    if not txt_files:
        print(f"âŒ {result_dir} í´ë”ì— txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“‚ ì´ {len(txt_files)}ê°œ txt íŒŒì¼ ë°œê²¬")
    print()

    # ì‹œì‘ ì‹œê°„
    start_time = time.time()

    # Semaphoreë¡œ ë™ì‹œ ì²˜ë¦¬ ê°œìˆ˜ ì œí•œ
    semaphore = asyncio.Semaphore(max_concurrent)

    async def process_with_semaphore(txt_file, idx):
        async with semaphore:
            return await process_single_file(
                txt_file=txt_file,
                api_key=api_key,
                model=model,
                max_tokens=max_tokens,
                idx=idx,
                total=len(txt_files)
            )

    # ëª¨ë“  íŒŒì¼ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
    tasks = [
        process_with_semaphore(txt_file, idx)
        for idx, txt_file in enumerate(txt_files, 1)
    ]

    # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
    results = await asyncio.gather(*tasks)

    # ê²°ê³¼ ì§‘ê³„
    success_count = sum(1 for success, _ in results if success)
    fail_count = len(results) - success_count

    # ì¢…ë£Œ ì‹œê°„
    end_time = time.time()
    elapsed_time = end_time - start_time

    # ìµœì¢… ê²°ê³¼
    print()
    print("=" * 80)
    print("ë³€í™˜ ì™„ë£Œ!")
    print("=" * 80)
    print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: result_txt/")
    print(f"â±ï¸  ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ ({elapsed_time/60:.2f}ë¶„)")
    print(f"âš¡ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {elapsed_time/len(txt_files):.2f}ì´ˆ/íŒŒì¼")
    print()

    # í† í° ì‚¬ìš©ëŸ‰ ì§‘ê³„ (result_txtì˜ JSON íŒŒì¼ì—ì„œ ì½ê¸°)
    total_input_tokens = 0
    total_output_tokens = 0

    result_txt_path = Path("result_txt")
    if result_txt_path.exists():
        import json
        for json_file in result_txt_path.glob("*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    usage = data.get('usage', {})
                    total_input_tokens += usage.get('input_tokens', 0)
                    total_output_tokens += usage.get('output_tokens', 0)
            except:
                pass

    if total_input_tokens > 0 or total_output_tokens > 0:
        print("ğŸ“Š ì´ í† í° ì‚¬ìš©ëŸ‰:")
        print(f"   ì…ë ¥: {total_input_tokens:,} tokens")
        print(f"   ì¶œë ¥: {total_output_tokens:,} tokens")
        print(f"   í•©ê³„: {total_input_tokens + total_output_tokens:,} tokens")
        print()


def main():
    """
    ë©”ì¸ í•¨ìˆ˜ - asyncio ì‹¤í–‰
    """
    # ë™ì‹œ ì²˜ë¦¬ ê°œìˆ˜ ì„¤ì • (í•„ìš” ì‹œ ì¡°ì •)
    # GeminiëŠ” rate limitì´ OpenAIë³´ë‹¤ ì—¬ìœ ë¡œì›Œì„œ ë” ë§ì´ ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥
    # - 10ê°œ: ê¶Œì¥ ê¸°ë³¸ê°’ (ë¹ ë¥´ê³  ì•ˆì •ì )
    # - 15ê°œ: ë§¤ìš° ë¹ ë¦„ (rate limit ì£¼ì˜)
    # - 5ê°œ: ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
    max_concurrent = 10

    # ìµœëŒ€ ì¶œë ¥ í† í° ì„¤ì •
    # - 65536: Gemini 2.5 Flash ìµœëŒ€ê°’ (ê¸´ íšŒì˜ë¡ë„ ì²˜ë¦¬ ê°€ëŠ¥)
    # - 32768: ì¤‘ê°„ê°’ (ëŒ€ë¶€ë¶„ì˜ íšŒì˜ë¡ ì²˜ë¦¬ ê°€ëŠ¥)
    # - 16384: ì‘ì€ ê°’ (ì§§ì€ íšŒì˜ë¡ìš©)
    max_tokens = 65536

    asyncio.run(process_all_txt_files_async(
        max_concurrent=max_concurrent,
        max_tokens=max_tokens
    ))


if __name__ == "__main__":
    main()
